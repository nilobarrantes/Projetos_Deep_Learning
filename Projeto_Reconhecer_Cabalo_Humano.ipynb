{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projeto-Reconhecer-Cabalo-Humano.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilobarrantes/Proyetos_Deep_Learning/blob/master/Projeto_Reconhecer_Cabalo_Humano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_9FipXiwAD_",
        "colab_type": "text"
      },
      "source": [
        "# **Cavalos vs Humanos**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1a7xwLCdqovYxoJq3M4CM8v6cZX-k16KT)\n",
        "\n",
        "O conjunto de dados Cavalos vs. Humanos é um conjunto de dados de visão computacional padrão que envolve a classificação de fotos como contendo um cavalo ou um humano.\n",
        "\n",
        "Embora o problema pareça simples, ele só foi abordado de forma eficaz nos últimos anos usando redes neurais convolucionais (CNN) de aprendizado profundo.\n",
        "\n",
        "### **Como funcionam as CNNs?**\n",
        "As redes convolucionais funcionam transformando os pixels de uma imagem em informações que podem ser entendidas pela máquina. As etapas envolvidas no reconhecimento de imagem são:\n",
        "\n",
        "\n",
        "\n",
        "* Convolution\n",
        "* Pooling\n",
        "* Flattening\n",
        "* Fully connected layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R40nXQHh0uuV",
        "colab_type": "text"
      },
      "source": [
        "## **Importando Imagens de Treinamento e validaçao.**\n",
        "Usaremos um conjunto de imagens (treinamento) para ``ensinar'' à rede neural a diferença entre um cavalo e um humano. Ou seja, o conjunto de treinamento são os dados usados para informar ao modelo de rede neural que 'é assim que se parece um cavalo', 'é assim que se parece um humano' etc.\n",
        "\n",
        "Outro conjunto de imagens (validação), será usado para testar se nossa rede, já treinada, consegue distinguir um cavalo de um humano. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXZT2UsyIVe_",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O /tmp/horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mLij6qde6Ox",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O /tmp/validation-horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9brUxyTpYZHy"
      },
      "source": [
        "O código python a seguir usará a biblioteca OS para usar as bibliotecas do sistema operacional, fornecendo acesso ao sistema de arquivos e a biblioteca zipfile, permitindo a descompactação dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLy3pthUS0D2",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/horse-or-human')\n",
        "local_zip = '/tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation-horse-or-human')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "O conteúdo do .zip é extraído para o diretório base `/ tmp / horse-or-human`, que por sua vez contém subdiretórios` horses` e `humanos`.\n",
        "\n",
        "Vamos definir cada um desses diretórios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NR_M9nWN-K8B",
        "colab": {}
      },
      "source": [
        "# Directory with our training horse pictures\n",
        "train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "train_human_dir = os.path.join('/tmp/horse-or-human/humans')\n",
        "\n",
        "# Directory with our training horse pictures\n",
        "validation_horse_dir = os.path.join('/tmp/validation-horse-or-human/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "validation_human_dir = os.path.join('/tmp/validation-horse-or-human/humans')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vMnIwYPW9vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_horse_names = os.listdir(train_horse_dir)\n",
        "train_human_names = os.listdir(train_human_dir)\n",
        "\n",
        "validation_horse_hames = os.listdir(validation_horse_dir)\n",
        "validation_human_names = os.listdir(validation_human_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Construindo um pequeno modelo do zero\n",
        "\n",
        "Mas antes de continuar, vamos começar a definir o modelo:\n",
        "\n",
        "A etapa 1 será importar a biblioteca TensorFlow.\n",
        "\n",
        "**TensorFlow** é uma biblioteca de código aberto compatível com Python para computaçao numérica que torna o *,achine learning* mais rápido e fácil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvfZg3LQbD-5",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BnhYCP4tdqjC"
      },
      "source": [
        "Em seguida, adicionamos camadas convolucionais e achatamos(flatten) o resultado final para alimentar as camadas densamente conectadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gokG5HKpdtzm"
      },
      "source": [
        "Finalmente, adicionamos as camadas densamente conectadas.\n",
        "\n",
        "Observe que, como estamos enfrentando um problema de classificação de duas classes, ou seja, um *problema de classificação binária*, finalizaremos  nossa rede com uma [ativação sigmoide](https://wikipedia.org/wiki/Sigmoid_function), de modo que a saída de nossa rede será um único escalar entre 0 e 1, codificando a probabilidade de que a imagem atual seja da classe 1 (em oposição à classe 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PixZ2s5QbYQ3",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "A chamada do método model.summary () imprime um resumo da rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ZKj8392nbgP",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "\n",
        "A coluna \"formato de saída\" mostra como o tamanho do seu mapa de carateristicas evolui em cada camada sucessiva. As camadas de **convolução** reduzem um pouco o tamanho dos mapas de carateristicas devido ao preenchimento, e cada camada de agrupamento (**pooling**) divide as dimensões pela metade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "A seguir, vamos configurar as especificações para o treinamento do modelo. Vamos treinar nosso modelo com a perda `binary_crossentropy`, porque é um problema de classificação binária e nossa ativação final é um sigmóide. Nós usaremos o otimizador `rmsprop` com uma taxa de aprendizagem de` 0,001`. Durante o treinamento, vamos monitorar a precisão da classificação.\n",
        "\n",
        "**NOTA**: Neste caso, usar o [algoritmo de otimização RMSprop](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) é preferível a [descida gradiente estocástico](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), porque o RMSprop automatiza o ajuste da taxa de aprendizagem para nós. (Outros otimizadores, como [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) e [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), também adaptarao automaticamente a taxa de aprendizagem durante o treinamento e funcionariam igualmente bem.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8DHWhFP_uhq3",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Pré-processamento de dados\n",
        "\n",
        "Vamos configurar geradores de dados que irão ler imagens em nossas pastas de origem, convertê-los em tensores `float32` e alimentá-los (com seus rótulos) para nossa rede. Teremos um gerador para as imagens de treinamento e outro para as imagens de validação. Nossos geradores produzirão lotes de imagens de tamanho 300x300 e seus rótulos (binários).\n",
        "\n",
        "Os dados que vão para as redes neurais geralmente devem ser normalizados para torná-los mais receptivos ao processamento pela rede. Em nosso caso, iremos pré-processar nossas imagens normalizando os valores de pixel para que fiquem no intervalo `[0, 1]` (originalmente todos os valores estão no intervalo `[0, 255]` intervalo).\n",
        "\n",
        "No Keras, isso pode ser feito por meio da classe `keras.preprocessing.image.ImageDataGenerator` usando o parâmetro` rescale`. Esta classe `ImageDataGenerator` permite que você instancie geradores de lotes de imagens aumentadas (e seus rótulos) via `.flow(data, labels)` ou `.flow_from_directory(directory)`. Esses geradores podem então ser usados ​​com os métodos do modelo Keras que aceitam geradores de dados como entradas: `fit`,` evaluate_generator` e `predict_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClebU9NJg99G",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/horse-or-human/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/tmp/validation-horse-or-human/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Treinamento\n",
        "Vamos treinar por 15 épocas (epoch) - isso pode levar alguns minutos para ser executado.\n",
        "\n",
        "*Loss* e *accuracy*  são ótimos indicadores do progresso do treinamento. Se intenta adivinhar a classificação dos dados de treinamento e, en seguida, compara-los com a etiqueta conhecida, calculando o resultado. O *accuracy* é a parte das suposições corretas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fb1_lgobv81m",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR5mCNcs_7G6",
        "colab_type": "text"
      },
      "source": [
        "Geralmente teremos exactitudes altas como 1.000, que es probablemente una señal de *overfiting*. El conjunto de validación es de 0.81, que está bastante bien, pero pongámoslo a prueba con unas imágenes reales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o6vSHzPR2ghH"
      },
      "source": [
        "### Rodando o modelo\n",
        "\n",
        "Agora vamos dar uma olhada na execução de uma predição usando o modelo. Este código permitirá que você escolha um ou mais arquivos do seu sistema de arquivos, ele os carregará e os executará no modelo, dando uma indicação se o objeto é um cavalo ou um humano."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DoWp43WxJDNT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "## Limpeza\n",
        "Para encerrar o kernel e liberar recursos de memória, executar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "651IgjLyo-Jx",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}